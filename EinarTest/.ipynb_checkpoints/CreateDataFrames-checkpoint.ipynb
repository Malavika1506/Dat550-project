{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import functions as fun\n",
    "from collections import Counter\n",
    "import ast\n",
    "import pickle\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import pydot\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint \n",
    "import pandas as pd\n",
    "import scipy as sp \n",
    "import string\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import sklearn.model_selection as ms\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorboard as ts\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimID</th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "      <th>claimURL</th>\n",
       "      <th>reason</th>\n",
       "      <th>categories</th>\n",
       "      <th>speaker</th>\n",
       "      <th>checker</th>\n",
       "      <th>tags</th>\n",
       "      <th>articleTitle</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>claimDate</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pomt-03627</td>\n",
       "      <td>Six out of 10 of the highest unemployment rate...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>/ohio/statements/2013/may/06/chris-redfern/ohi...</td>\n",
       "      <td>When a couple of Statehouse Republicans prepar...</td>\n",
       "      <td>None</td>\n",
       "      <td>Chris Redfern</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2013-05-06T06:00:00</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>['None']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pomt-09611</td>\n",
       "      <td>No Democratic campaign for (Fla.) governor has...</td>\n",
       "      <td>true</td>\n",
       "      <td>/florida/statements/2010/jan/15/alex-sink/flor...</td>\n",
       "      <td>Florida's leading Republican candidate for gov...</td>\n",
       "      <td>None</td>\n",
       "      <td>Alex Sink</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-15T13:59:00</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>['None']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tron-00214</td>\n",
       "      <td>Forward an email for Jasmine</td>\n",
       "      <td>fiction!</td>\n",
       "      <td>https://www.truthorfiction.com/jasmine/</td>\n",
       "      <td>None</td>\n",
       "      <td>9-11-attack</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Forward an email for Jasmine</td>\n",
       "      <td>Mar 17, 2015</td>\n",
       "      <td>None</td>\n",
       "      <td>['None']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snes-04484</td>\n",
       "      <td>Pope Francis endorsed Donald Trump for president.</td>\n",
       "      <td>false</td>\n",
       "      <td>https://www.snopes.com/fact-check/pope-francis...</td>\n",
       "      <td>None</td>\n",
       "      <td>Junk News</td>\n",
       "      <td>None</td>\n",
       "      <td>Dan Evon</td>\n",
       "      <td>None</td>\n",
       "      <td>Pope Francis Shocks World, Endorses Donald Tru...</td>\n",
       "      <td>10 July 2016</td>\n",
       "      <td>None</td>\n",
       "      <td>['None']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pomt-06704</td>\n",
       "      <td>Says Ron Paul insisted FEMA should be shut down.</td>\n",
       "      <td>true</td>\n",
       "      <td>/texas/statements/2011/sep/03/maureen-dowd/mau...</td>\n",
       "      <td>Commenting on the federal response to Hurrican...</td>\n",
       "      <td>None</td>\n",
       "      <td>Maureen Dowd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-09-03T06:00:00</td>\n",
       "      <td>2011-08-30</td>\n",
       "      <td>['None']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      claimID                                              claim      label  \\\n",
       "0  pomt-03627  Six out of 10 of the highest unemployment rate...  half-true   \n",
       "1  pomt-09611  No Democratic campaign for (Fla.) governor has...       true   \n",
       "2  tron-00214                       Forward an email for Jasmine   fiction!   \n",
       "3  snes-04484  Pope Francis endorsed Donald Trump for president.      false   \n",
       "4  pomt-06704   Says Ron Paul insisted FEMA should be shut down.       true   \n",
       "\n",
       "                                            claimURL  \\\n",
       "0  /ohio/statements/2013/may/06/chris-redfern/ohi...   \n",
       "1  /florida/statements/2010/jan/15/alex-sink/flor...   \n",
       "2            https://www.truthorfiction.com/jasmine/   \n",
       "3  https://www.snopes.com/fact-check/pope-francis...   \n",
       "4  /texas/statements/2011/sep/03/maureen-dowd/mau...   \n",
       "\n",
       "                                              reason   categories  \\\n",
       "0  When a couple of Statehouse Republicans prepar...         None   \n",
       "1  Florida's leading Republican candidate for gov...         None   \n",
       "2                                               None  9-11-attack   \n",
       "3                                               None    Junk News   \n",
       "4  Commenting on the federal response to Hurrican...         None   \n",
       "\n",
       "         speaker   checker  tags  \\\n",
       "0  Chris Redfern      None  None   \n",
       "1      Alex Sink      None  None   \n",
       "2           None      None  None   \n",
       "3           None  Dan Evon  None   \n",
       "4   Maureen Dowd      None  None   \n",
       "\n",
       "                                        articleTitle          publishDate  \\\n",
       "0                                               None  2013-05-06T06:00:00   \n",
       "1                                               None  2010-01-15T13:59:00   \n",
       "2                       Forward an email for Jasmine         Mar 17, 2015   \n",
       "3  Pope Francis Shocks World, Endorses Donald Tru...         10 July 2016   \n",
       "4                                               None  2011-09-03T06:00:00   \n",
       "\n",
       "    claimDate  entities  \n",
       "0  2013-04-30  ['None']  \n",
       "1  2010-01-06  ['None']  \n",
       "2        None  ['None']  \n",
       "3        None  ['None']  \n",
       "4  2011-08-30  ['None']  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = ['claimID', 'claim', 'label', 'claimURL', 'reason', 'categories', 'speaker', 'checker', 'tags', 'articleTitle', 'publishDate', 'claimDate', 'entities']\n",
    "df_train = pd.read_csv('../data/train.tsv',sep='\\t',names=h,header=None)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>snip_1</th>\n",
       "      <th>snip_2</th>\n",
       "      <th>snip_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claimID</th>\n",
       "      <th>snip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">abbc-00001</th>\n",
       "      <th>2</th>\n",
       "      <td>Record numbers march down Brisbane city to pro...</td>\n",
       "      <td>Sep 4, 2018 ... THOUSANDS of people joined the...</td>\n",
       "      <td>http://catholicleader.com.au/news/record-numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fact check: Will Queensland's proposed abortio...</td>\n",
       "      <td>Oct 3, 2018 ... Protestors have marched throug...</td>\n",
       "      <td>http://abortion-news.info/fact-check-will-quee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queensland Council for Civil Liberties - Wikip...</td>\n",
       "      <td>The Queensland Council for Civil Liberties (QC...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Queensland_Counc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abortion law change expected from Queensland L...</td>\n",
       "      <td>Jun 28, 2018 ... The Queensland Law Reform Com...</td>\n",
       "      <td>http://www.abc.net.au/news/2018-06-29/abortion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Struggle</td>\n",
       "      <td>enforcing the State‟s controversial anti-march...</td>\n",
       "      <td>https://www.childrenbychoice.org.au/images/dow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               snip_1  \\\n",
       "claimID    snip_id                                                      \n",
       "abbc-00001 2        Record numbers march down Brisbane city to pro...   \n",
       "           3        Fact check: Will Queensland's proposed abortio...   \n",
       "           4        Queensland Council for Civil Liberties - Wikip...   \n",
       "           5        Abortion law change expected from Queensland L...   \n",
       "           6                                             The Struggle   \n",
       "\n",
       "                                                               snip_2  \\\n",
       "claimID    snip_id                                                      \n",
       "abbc-00001 2        Sep 4, 2018 ... THOUSANDS of people joined the...   \n",
       "           3        Oct 3, 2018 ... Protestors have marched throug...   \n",
       "           4        The Queensland Council for Civil Liberties (QC...   \n",
       "           5        Jun 28, 2018 ... The Queensland Law Reform Com...   \n",
       "           6        enforcing the State‟s controversial anti-march...   \n",
       "\n",
       "                                                             snip_url  \n",
       "claimID    snip_id                                                     \n",
       "abbc-00001 2        http://catholicleader.com.au/news/record-numbe...  \n",
       "           3        http://abortion-news.info/fact-check-will-quee...  \n",
       "           4        https://en.wikipedia.org/wiki/Queensland_Counc...  \n",
       "           5        http://www.abc.net.au/news/2018-06-29/abortion...  \n",
       "           6        https://www.childrenbychoice.org.au/images/dow...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = ['snip_id', 'snip_1', 'snip_2','snip_url']\n",
    "df_snip =  pd.DataFrame(columns=h)\n",
    "\n",
    "\n",
    "dir = '..\\data\\snippets'\n",
    "for filename in os.listdir(dir):\n",
    "    \n",
    "    df_row = pd.read_csv(os.path.join(dir, filename),names=h,sep='\\t',header=None,engine='python',encoding='utf8' ,quoting=3)\n",
    "    df_row.insert(loc = 0, column = 'claimID', value = filename )\n",
    "    \n",
    "    df_snip = df_snip.append(df_row)\n",
    "\n",
    "df_snip.set_index(['claimID','snip_id'],inplace = False).head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training df to pickle.  (Remove rows with missing snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (24004, 13)\n",
      "Snip shape: (219021, 5) Unique: 24004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_snip = df_snip.loc[df_snip['claimID'].isin(df_train.claimID)]\n",
    "df_train = df_train.loc[df_train['claimID'].isin(df_snip['claimID'].unique())]\n",
    "\n",
    "\n",
    "print('train shape:',np.shape(df_train))\n",
    "print('Snip shape:',np.shape(df_snip),'Unique:',len(df_snip['claimID'].unique()))\n",
    "\n",
    "df_train.set_index('claimID',inplace = True)\n",
    "df_snip.set_index(['claimID','snip_id'],inplace = True)\n",
    "\n",
    "\n",
    "df_snip.to_pickle(\"./df_snip.pkl\")\n",
    "df_train.to_pickle(\"./df_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snip = pd.read_pickle(\"./df_snip.pkl\")\n",
    "#df_train = pd.read_pickle(\"./df_train.pkl\")\n",
    "\n",
    "#df_train.reset_index(drop=False, inplace=True)\n",
    "#df_snip.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num =  df_train['label'].astype(\"category\").cat.codes.values\n",
    "\n",
    "with open('y_train_num','wb') as i:\n",
    "       pickle.dump(y_train_num, i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_train[['claimURL','speaker','checker']].copy() \n",
    "\n",
    "\n",
    "#df_meta['articleTitle'] = df_meta['articleTitle'].str.lower()\n",
    "\n",
    "df_meta['claimURL'] = df_meta.apply(lambda x: fun.clean_url(x.claimURL),axis=1)\n",
    "\n",
    "df_meta['claimURL'] = df_meta['claimURL'].astype(\"category\").cat.codes.values\n",
    "\n",
    "df_meta['speaker'] = df_meta['speaker'].astype(\"category\").cat.codes.values\n",
    "df_meta['checker'] = df_meta['checker'].astype(\"category\").cat.codes.values\n",
    "\n",
    "    \n",
    "df_meta.head() \n",
    "\n",
    "X_metadata = df_meta.to_numpy()\n",
    "\n",
    "bin_enteties = fun.create_binary(df_train['entities'],30)\n",
    "\n",
    "tags = df_train.apply(lambda x: str(x.tags).replace('[','').replace(']','').replace(\"'\",'').split(',')   ,axis=1)\n",
    "\n",
    "bin_tags = fun.create_binary(tags,30)\n",
    "\n",
    "\n",
    "\n",
    "X_metadata = np.append(X_metadata, bin_enteties, axis=1)\n",
    "\n",
    "with open('X_meta','wb') as i:\n",
    "       pickle.dump(X_metadata, i)\n",
    "\n",
    "\n",
    "df_meta_num = pd.DataFrame(data = np.hstack((df_train.index.to_numpy().reshape(-1,1),X_metadata))     )        \n",
    "        \n",
    "with open('df_meta_num','wb') as i:\n",
    "       pickle.dump(df_meta_num, i)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claim = df_train['claim'].str.lower().copy()\n",
    "\n",
    "words_list = [i if type(i)==str else '' for i in df_claim]\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(words_list)\n",
    "\n",
    "sequences = t.texts_to_sequences(words_list)\n",
    "\n",
    "X_claim = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "\n",
    "with open('X_claim','wb') as i:\n",
    "       pickle.dump(X_claim, i)\n",
    "            \n",
    "\n",
    "            \n",
    "df_claim_num = pd.DataFrame(data = np.hstack((df_train.index.to_numpy().reshape(-1,1),X_claim))   )        \n",
    "        \n",
    "with open('df_claim_num','wb') as i:\n",
    "       pickle.dump(df_claim_num, i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snippet set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snip['snip_url'] = df_snip.apply(lambda x: fun.clean_url(x.snip_url),axis=1)\n",
    "\n",
    "df_snip['snip_1'] = df_snip['snip_1'].str.lower()\n",
    "df_snip['snip_2'] = df_snip['snip_2'].str.lower()\n",
    "\n",
    "df_snip['snip_url'] = df_snip['snip_url'].astype(\"category\").cat.codes.values\n",
    "\n",
    "\n",
    "df_snip.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words_list1 = [i if type(i)==str else '' for i in df_snip['snip_1']]\n",
    "sequences1 = t.texts_to_sequences(words_list1)\n",
    "snip1 = tf.keras.preprocessing.sequence.pad_sequences(sequences1, maxlen=20)\n",
    "\n",
    "words_list2 = [i if type(i)==str else '' for i in df_snip['snip_2']]\n",
    "sequences2 = t.texts_to_sequences(words_list2)\n",
    "snip2 = tf.keras.preprocessing.sequence.pad_sequences(sequences2, maxlen=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "snip_info = df_snip[['claimID','snip_id','snip_url']].to_numpy()\n",
    "snip = np.append(snip_info, np.append(snip1,snip2,axis=1), axis=1)\n",
    "\n",
    "\n",
    "df_snip_num =pd.DataFrame(data=snip)\n",
    "df_snip_num\n",
    "\n",
    "with open('df_snip_num','wb') as i:\n",
    "       pickle.dump(df_snip_num, i) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbc-00002</td>\n",
       "      <td>2</td>\n",
       "      <td>20830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>776</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbc-00002</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>3849</td>\n",
       "      <td>681</td>\n",
       "      <td>5</td>\n",
       "      <td>2501</td>\n",
       "      <td>2372</td>\n",
       "      <td>12</td>\n",
       "      <td>13286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbc-00002</td>\n",
       "      <td>4</td>\n",
       "      <td>7987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>448</td>\n",
       "      <td>624</td>\n",
       "      <td>17744</td>\n",
       "      <td>12</td>\n",
       "      <td>1724</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbc-00002</td>\n",
       "      <td>5</td>\n",
       "      <td>8442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>349</td>\n",
       "      <td>626</td>\n",
       "      <td>136</td>\n",
       "      <td>34</td>\n",
       "      <td>166</td>\n",
       "      <td>6</td>\n",
       "      <td>589</td>\n",
       "      <td>10</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbc-00002</td>\n",
       "      <td>6</td>\n",
       "      <td>21017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "      <td>6907</td>\n",
       "      <td>7814</td>\n",
       "      <td>714</td>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>5018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1      2   3   4   5   6   7   8   9    ... 93   94   95    96   \\\n",
       "0  abbc-00002   2  20830   0   0   0   0   0   0   0  ...   5    1  776   100   \n",
       "1  abbc-00002   3    175   0   0   0   0   0   0   0  ...  59  580    1  3849   \n",
       "2  abbc-00002   4   7987   0   0   0   0   0   0   0  ...  69    5  448   624   \n",
       "3  abbc-00002   5   8442   0   0   0   0   0   0   0  ...   5  349  626   136   \n",
       "4  abbc-00002   6  21017   0   0   0   0   0   0   0  ...   1  165    5  6907   \n",
       "\n",
       "     97   98    99    100   101    102  \n",
       "0      8   93    16   186     5    452  \n",
       "1    681    5  2501  2372    12  13286  \n",
       "2  17744   12  1724     1   256    493  \n",
       "3     34  166     6   589    10   1188  \n",
       "4   7814  714     1  1953  5018      2  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snip_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Snippet set (very very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snippet_list = []\n",
    "\n",
    "for q,i in enumerate(df_train.index):\n",
    "\n",
    "    row = []\n",
    "    for i,r in df_snip_num[ df_snip_num[0]==i].iterrows():\n",
    "       \n",
    "        row.append(r[1:].to_list())\n",
    "    row = [snip for snippets in row for snip in snippets]\n",
    "    \n",
    "    snippet_list.append(row)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_snip_flat =  tf.keras.preprocessing.sequence.pad_sequences(snippet_list, maxlen=1005)\n",
    "\n",
    "with open('X_snip_flat','wb') as i:\n",
    "       pickle.dump(X_snip_flat, i) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim (24004, 50)\n",
      "meta (24004, 33)\n",
      "snip flat (24004, 1005)\n",
      "y (24004,)\n"
     ]
    }
   ],
   "source": [
    "print('claim',np.shape(X_claim))\n",
    "print('meta',np.shape(X_metadata))\n",
    "print('snip flat',np.shape(X_snip_flat))\n",
    "print('y',np.shape(y_train_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
